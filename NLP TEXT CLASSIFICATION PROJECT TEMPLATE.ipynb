{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLP TEXT CLASSIFICATION PROJECT TEMPLATE\n",
    "==========================================\n",
    "Use Case: Sentiment Analysis, Topic Classification, Spam Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PROJECT SETUP & ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# NLP specific\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "# Deep Learning (optional)\n",
    "# from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "# import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download required NLTK data\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configuration & Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'random_state': 42,\n",
    "    'test_size': 0.2,\n",
    "    'val_size': 0.1,\n",
    "    'max_features': 5000,\n",
    "    'max_len': 128,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 10,\n",
    "    'learning_rate': 2e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "df = pd.read_csv('your_data.csv')\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(df.info())\n",
    "print(\"\\n\", df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(\"\\nMissing values:\\n\", df.isnull().sum())\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nClass distribution:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "# Visualize class distribution\n",
    "plt.figure(figsize=(10, 5))\n",
    "df['label'].value_counts().plot(kind='bar')\n",
    "plt.title('Class Distribution')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text length analysis\n",
    "df['text_length'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "df['text_length'].hist(bins=50, ax=axes[0])\n",
    "axes[0].set_title('Character Length Distribution')\n",
    "df['word_count'].hist(bins=50, ax=axes[1])\n",
    "axes[1].set_title('Word Count Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Text Cleaning Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    \"\"\"Clean and preprocess text data\"\"\"\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)\n",
    "    \n",
    "    # Remove mentions and hashtags\n",
    "    text = re.sub(r'@\\w+|#\\w+', '', text)\n",
    "    \n",
    "    # Remove special characters and digits\n",
    "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
    "    \n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply cleaning\n",
    "df['cleaned_text'] = df['text'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Tokenization & Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Tokenize, remove stopwords, and lemmatize\"\"\"\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens \n",
    "              if token not in stop_words and len(token) > 2]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['processed_text'] = df['cleaned_text'].apply(preprocess_text)\n",
    "df[['text', 'cleaned_text', 'processed_text']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. FEATURE ENGINEERING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Text Vectorization (Choose One)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: TF-IDF Vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer(max_features=CONFIG['max_features'], ngram_range=(1, 2))\n",
    "X = tfidf.fit_transform(df['processed_text'])\n",
    "y = df['label']\n",
    "\n",
    "print(f\"Feature matrix shape: {X.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Word Embeddings (Word2Vec)\n",
    "# from gensim.models import Word2Vec\n",
    "# \n",
    "# sentences = [text.split() for text in df['processed_text']]\n",
    "# w2v_model = Word2Vec(sentences, vector_size=100, window=5, min_count=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 3: Transformer Tokenization (BERT, RoBERTa, etc.)\n",
    "# tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "# encodings = tokenizer(df['processed_text'].tolist(), truncation=True, \n",
    "#                       padding=True, max_length=CONFIG['max_len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. DATA SPLITTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=CONFIG['test_size'], \n",
    "    random_state=CONFIG['random_state'], stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Test set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. MODEL BUILDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Baseline Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "nb_pred = nb_model.predict(X_test)\n",
    "print(\"Naive Bayes Accuracy:\", accuracy_score(y_test, nb_pred))\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=CONFIG['random_state'])\n",
    "lr_model.fit(X_train, y_train)\n",
    "lr_pred = lr_model.predict(X_test)\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, lr_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Deep Learning Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
    "# \n",
    "# model = Sequential([\n",
    "#     Embedding(input_dim=CONFIG['max_features'], output_dim=128, input_length=CONFIG['max_len']),\n",
    "#     Bidirectional(LSTM(64, return_sequences=True)),\n",
    "#     Dropout(0.5),\n",
    "#     Bidirectional(LSTM(32)),\n",
    "#     Dense(64, activation='relu'),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(num_classes, activation='softmax')\n",
    "# ])\n",
    "# \n",
    "# model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "# history = model.fit(X_train, y_train, validation_split=0.2, \n",
    "#                     epochs=CONFIG['epochs'], batch_size=CONFIG['batch_size'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. MODEL EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose best model for evaluation\n",
    "best_model = lr_model\n",
    "y_pred = lr_pred\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_scores = cross_val_score(best_model, X_train, y_train, cv=5)\n",
    "print(f\"Cross-validation scores: {cv_scores}\")\n",
    "print(f\"Mean CV accuracy: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. MODEL INTERPRETATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance (for logistic regression with TF-IDF)\n",
    "if hasattr(best_model, 'coef_'):\n",
    "    feature_names = tfidf.get_feature_names_out()\n",
    "    top_positive_features = np.argsort(best_model.coef_[0])[-10:]\n",
    "    top_negative_features = np.argsort(best_model.coef_[0])[:10]\n",
    "    \n",
    "    print(\"Top positive features:\")\n",
    "    for idx in top_positive_features:\n",
    "        print(f\"{feature_names[idx]}: {best_model.coef_[0][idx]:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop negative features:\")\n",
    "    for idx in top_negative_features:\n",
    "        print(f\"{feature_names[idx]}: {best_model.coef_[0][idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. PREDICTION PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_text(text, model=best_model, vectorizer=tfidf):\n",
    "    \"\"\"Predict label for new text\"\"\"\n",
    "    cleaned = clean_text(text)\n",
    "    processed = preprocess_text(cleaned)\n",
    "    vectorized = vectorizer.transform([processed])\n",
    "    prediction = model.predict(vectorized)[0]\n",
    "    probability = model.predict_proba(vectorized)[0]\n",
    "    return prediction, probability\n",
    "\n",
    "# Test the pipeline\n",
    "sample_text = \"This is a sample text to classify\"\n",
    "pred, proba = predict_text(sample_text)\n",
    "print(f\"Prediction: {pred}\")\n",
    "print(f\"Probabilities: {proba}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. MODEL SAVING & DEPLOYMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save model and vectorizer\n",
    "joblib.dump(best_model, 'text_classifier_model.pkl')\n",
    "joblib.dump(tfidf, 'tfidf_vectorizer.pkl')\n",
    "\n",
    "# Load model\n",
    "# loaded_model = joblib.load('text_classifier_model.pkl')\n",
    "# loaded_vectorizer = joblib.load('tfidf_vectorizer.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. CONCLUSIONS & NEXT STEPS\n",
    "\n",
    "## Summary:\n",
    "- Dataset size: X samples\n",
    "- Best model: [Model Name]\n",
    "- Test accuracy: X.XX%\n",
    "- Key findings: [Your insights]\n",
    "\n",
    "## Next Steps:\n",
    "- [ ] Try different preprocessing techniques\n",
    "- [ ] Experiment with advanced models (BERT, GPT)\n",
    "- [ ] Collect more training data\n",
    "- [ ] Implement data augmentation\n",
    "- [ ] Deploy to production\n",
    "- [ ] Monitor model performance"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
