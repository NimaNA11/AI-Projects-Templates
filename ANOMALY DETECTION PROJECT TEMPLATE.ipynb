{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ANOMALY DETECTION PROJECT TEMPLATE\n",
    "===================================\n",
    "Use Case: Fraud Detection, Network Intrusion, Equipment Failure Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. PROJECT SETUP & ENVIRONMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import IsolationForest, RandomForestClassifier\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.metrics import (\n",
    "    classification_report, confusion_matrix, \n",
    "    precision_recall_curve, roc_auc_score, roc_curve,\n",
    "    f1_score, precision_score, recall_score\n",
    ")\n",
    "\n",
    "# Deep Learning\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seeds\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG = {\n",
    "    'data_path': 'data.csv',\n",
    "    'contamination': 0.05,  # Expected proportion of anomalies\n",
    "    'test_size': 0.2,\n",
    "    'batch_size': 128,\n",
    "    'learning_rate': 0.001,\n",
    "    'num_epochs': 100,\n",
    "    'latent_dim': 8,\n",
    "    'threshold_percentile': 95,\n",
    "    'random_seed': 42\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. DATA LOADING & EXPLORATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(CONFIG['data_path'])\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"\\nColumn types:\")\n",
    "print(df.dtypes)\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values:\\n{df.isnull().sum()}\")\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nDuplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of features\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "\n",
    "fig, axes = plt.subplots(len(numeric_cols)//4 + 1, 4, figsize=(20, 5*len(numeric_cols)//4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].hist(df[col].dropna(), bins=50, edgecolor='black')\n",
    "    axes[idx].set_title(f'Distribution of {col}')\n",
    "    axes[idx].set_xlabel(col)\n",
    "    axes[idx].set_ylabel('Frequency')\n",
    "\n",
    "for idx in range(len(numeric_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation matrix\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=False, cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Box plots for outlier visualization\n",
    "fig, axes = plt.subplots(len(numeric_cols)//4 + 1, 4, figsize=(20, 5*len(numeric_cols)//4))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for idx, col in enumerate(numeric_cols):\n",
    "    axes[idx].boxplot(df[col].dropna())\n",
    "    axes[idx].set_title(f'Box Plot: {col}')\n",
    "    axes[idx].set_ylabel(col)\n",
    "\n",
    "for idx in range(len(numeric_cols), len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill or drop missing values\n",
    "df_clean = df.fillna(df.median(numeric_only=True))\n",
    "\n",
    "# Alternative: forward fill for time series\n",
    "# df_clean = df.fillna(method='ffill')\n",
    "\n",
    "print(f\"Missing values after cleaning: {df_clean.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(df):\n",
    "    \"\"\"Create additional features for anomaly detection\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    # Statistical features\n",
    "    for col in numeric_cols:\n",
    "        # Rolling statistics\n",
    "        df[f'{col}_rolling_mean_3'] = df[col].rolling(window=3, min_periods=1).mean()\n",
    "        df[f'{col}_rolling_std_3'] = df[col].rolling(window=3, min_periods=1).std()\n",
    "        \n",
    "        # Lag features\n",
    "        df[f'{col}_lag_1'] = df[col].shift(1)\n",
    "        \n",
    "        # Difference\n",
    "        df[f'{col}_diff'] = df[col].diff()\n",
    "    \n",
    "    return df.fillna(0)\n",
    "\n",
    "df_engineered = create_features(df_clean)\n",
    "print(f\"Features after engineering: {df_engineered.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features and (if available) labels\n",
    "feature_cols = df_engineered.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# If you have labels (supervised case)\n",
    "if 'label' in df_engineered.columns:\n",
    "    X = df_engineered[feature_cols].drop('label', axis=1)\n",
    "    y = df_engineered['label']\n",
    "    supervised = True\n",
    "else:\n",
    "    X = df_engineered[feature_cols]\n",
    "    y = None\n",
    "    supervised = False\n",
    "\n",
    "# Scale features\n",
    "scaler = RobustScaler()  # Robust to outliers\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns, index=X.index)\n",
    "\n",
    "print(f\"Feature matrix shape: {X_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. TRAIN-TEST SPLIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if supervised:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X_scaled, y, test_size=CONFIG['test_size'], \n",
    "        random_state=CONFIG['random_seed'], stratify=y\n",
    "    )\n",
    "else:\n",
    "    # For unsupervised, split without labels\n",
    "    split_idx = int(len(X_scaled) * (1 - CONFIG['test_size']))\n",
    "    X_train = X_scaled.iloc[:split_idx]\n",
    "    X_test = X_scaled.iloc[split_idx:]\n",
    "    y_train, y_test = None, None\n",
    "\n",
    "print(f\"Train shape: {X_train.shape}\")\n",
    "print(f\"Test shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. UNSUPERVISED ANOMALY DETECTION METHODS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iso_forest = IsolationForest(\n",
    "    contamination=CONFIG['contamination'],\n",
    "    random_state=CONFIG['random_seed'],\n",
    "    n_estimators=100\n",
    ")\n",
    "\n",
    "iso_forest.fit(X_train)\n",
    "iso_pred_train = iso_forest.predict(X_train)\n",
    "iso_pred_test = iso_forest.predict(X_test)\n",
    "\n",
    "# Convert to binary (1: normal, -1: anomaly -> 0: normal, 1: anomaly)\n",
    "iso_pred_train = (iso_pred_train == -1).astype(int)\n",
    "iso_pred_test = (iso_pred_test == -1).astype(int)\n",
    "\n",
    "print(f\"Isolation Forest - Training anomalies: {iso_pred_train.sum()}\")\n",
    "print(f\"Isolation Forest - Test anomalies: {iso_pred_test.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ocsvm = OneClassSVM(nu=CONFIG['contamination'], kernel='rbf', gamma='auto')\n",
    "ocsvm.fit(X_train)\n",
    "\n",
    "ocsvm_pred_train = ocsvm.predict(X_train)\n",
    "ocsvm_pred_test = ocsvm.predict(X_test)\n",
    "\n",
    "ocsvm_pred_train = (ocsvm_pred_train == -1).astype(int)\n",
    "ocsvm_pred_test = (ocsvm_pred_test == -1).astype(int)\n",
    "\n",
    "print(f\"One-Class SVM - Training anomalies: {ocsvm_pred_train.sum()}\")\n",
    "print(f\"One-Class SVM - Test anomalies: {ocsvm_pred_test.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 Local Outlier Factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lof = LocalOutlierFactor(contamination=CONFIG['contamination'], novelty=True)\n",
    "lof.fit(X_train)\n",
    "\n",
    "lof_pred_train = lof.predict(X_train)\n",
    "lof_pred_test = lof.predict(X_test)\n",
    "\n",
    "lof_pred_train = (lof_pred_train == -1).astype(int)\n",
    "lof_pred_test = (lof_pred_test == -1).astype(int)\n",
    "\n",
    "print(f\"LOF - Training anomalies: {lof_pred_train.sum()}\")\n",
    "print(f\"LOF - Test anomalies: {lof_pred_test.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. AUTOENCODER FOR ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Autoencoder Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"Deep Autoencoder for anomaly detection\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim=8):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, latent_dim)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, input_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "# Initialize model\n",
    "input_dim = X_train.shape[1]\n",
    "autoencoder = Autoencoder(input_dim, CONFIG['latent_dim']).to(device)\n",
    "\n",
    "print(autoencoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Variational Autoencoder (VAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \"\"\"Variational Autoencoder for anomaly detection\"\"\"\n",
    "    def __init__(self, input_dim, latent_dim=8):\n",
    "        super(VAE, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        \n",
    "        # Latent space\n",
    "        self.fc_mu = nn.Linear(64, latent_dim)\n",
    "        self.fc_logvar = nn.Linear(64, latent_dim)\n",
    "        \n",
    "        # Decoder\n",
    "        self.fc3 = nn.Linear(latent_dim, 64)\n",
    "        self.fc4 = nn.Linear(64, 128)\n",
    "        self.fc5 = nn.Linear(128, input_dim)\n",
    "    \n",
    "    def encode(self, x):\n",
    "        h = F.relu(self.fc1(x))\n",
    "        h = F.relu(self.fc2(h))\n",
    "        return self.fc_mu(h), self.fc_logvar(h)\n",
    "    \n",
    "    def reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc3(z))\n",
    "        h = F.relu(self.fc4(h))\n",
    "        return self.fc5(h)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 Training Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to tensors\n",
    "X_train_tensor = torch.FloatTensor(X_train.values).to(device)\n",
    "X_test_tensor = torch.FloatTensor(X_test.values).to(device)\n",
    "\n",
    "# Training setup\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(autoencoder.parameters(), lr=CONFIG['learning_rate'])\n",
    "\n",
    "# Training loop\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "\n",
    "for epoch in range(CONFIG['num_epochs']):\n",
    "    # Training\n",
    "    autoencoder.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    outputs = autoencoder(X_train_tensor)\n",
    "    loss = criterion(outputs, X_train_tensor)\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    autoencoder.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = autoencoder(X_test_tensor)\n",
    "        test_loss = criterion(test_outputs, X_test_tensor)\n",
    "        test_losses.append(test_loss.item())\n",
    "    \n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{CONFIG[\"num_epochs\"]}], '\n",
    "              f'Train Loss: {loss.item():.6f}, Test Loss: {test_loss.item():.6f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(test_losses, label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('MSE Loss')\n",
    "plt.title('Autoencoder Training History')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.4 Compute Reconstruction Error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    # Training set\n",
    "    train_reconstructions = autoencoder(X_train_tensor)\n",
    "    train_mse = torch.mean((X_train_tensor - train_reconstructions) ** 2, dim=1)\n",
    "    train_mse = train_mse.cpu().numpy()\n",
    "    \n",
    "    # Test set\n",
    "    test_reconstructions = autoencoder(X_test_tensor)\n",
    "    test_mse = torch.mean((X_test_tensor - test_reconstructions) ** 2, dim=1)\n",
    "    test_mse = test_mse.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize reconstruction error distribution\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_mse, bins=50, alpha=0.7, label='Train', edgecolor='black')\n",
    "plt.hist(test_mse, bins=50, alpha=0.7, label='Test', edgecolor='black')\n",
    "plt.xlabel('Reconstruction Error (MSE)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Reconstruction Error')\n",
    "plt.legend()\n",
    "plt.yscale('log')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot([train_mse, test_mse], labels=['Train', 'Test'])\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error Box Plot')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Set Threshold and Detect Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set threshold based on training data\n",
    "threshold = np.percentile(train_mse, CONFIG['threshold_percentile'])\n",
    "print(f\"Anomaly threshold (MSE): {threshold:.6f}\")\n",
    "\n",
    "# Detect anomalies\n",
    "ae_pred_train = (train_mse > threshold).astype(int)\n",
    "ae_pred_test = (test_mse > threshold).astype(int)\n",
    "\n",
    "print(f\"Autoencoder - Training anomalies: {ae_pred_train.sum()}\")\n",
    "print(f\"Autoencoder - Test anomalies: {ae_pred_test.sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. MODEL EVALUATION (if labels available)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if supervised and y_test is not None:\n",
    "    print(\"\\n=== ISOLATION FOREST ===\")\n",
    "    print(classification_report(y_test, iso_pred_test))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, iso_pred_test):.4f}\")\n",
    "    \n",
    "    print(\"\\n=== ONE-CLASS SVM ===\")\n",
    "    print(classification_report(y_test, ocsvm_pred_test))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, ocsvm_pred_test):.4f}\")\n",
    "    \n",
    "    print(\"\\n=== LOCAL OUTLIER FACTOR ===\")\n",
    "    print(classification_report(y_test, lof_pred_test))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, lof_pred_test):.4f}\")\n",
    "    \n",
    "    print(\"\\n=== AUTOENCODER ===\")\n",
    "    print(classification_report(y_test, ae_pred_test))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, ae_pred_test):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Confusion Matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if supervised and y_test is not None:\n",
    "    models = {\n",
    "        'Isolation Forest': iso_pred_test,\n",
    "        'One-Class SVM': ocsvm_pred_test,\n",
    "        'LOF': lof_pred_test,\n",
    "        'Autoencoder': ae_pred_test\n",
    "    }\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    for idx, (name, preds) in enumerate(models.items()):\n",
    "        cm = confusion_matrix(y_test, preds)\n",
    "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[idx])\n",
    "        axes[idx].set_title(f'{name} - Confusion Matrix')\n",
    "        axes[idx].set_ylabel('True Label')\n",
    "        axes[idx].set_xlabel('Predicted Label')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 ROC Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if supervised and y_test is not None:\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # For models that provide anomaly scores\n",
    "    iso_scores = iso_forest.score_samples(X_test)\n",
    "    ocsvm_scores = ocsvm.score_samples(X_test)\n",
    "    lof_scores = lof.score_samples(X_test)\n",
    "    ae_scores = -test_mse  # Negative because lower MSE = more normal\n",
    "    \n",
    "    models_scores = {\n",
    "        'Isolation Forest': iso_scores,\n",
    "        'One-Class SVM': ocsvm_scores,\n",
    "        'LOF': lof_scores,\n",
    "        'Autoencoder': ae_scores\n",
    "    }\n",
    "    \n",
    "    for name, scores in models_scores.items():\n",
    "        fpr, tpr, _ = roc_curve(y_test, scores)\n",
    "        auc = roc_auc_score(y_test, scores)\n",
    "        plt.plot(fpr, tpr, label=f'{name} (AUC = {auc:.3f})', linewidth=2)\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC Curves Comparison')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. ENSEMBLE ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_predictions(predictions_dict, method='majority'):\n",
    "    \"\"\"Combine predictions from multiple models\"\"\"\n",
    "    predictions_array = np.array(list(predictions_dict.values()))\n",
    "    \n",
    "    if method == 'majority':\n",
    "        # Majority voting\n",
    "        ensemble = (predictions_array.sum(axis=0) > len(predictions_dict) / 2).astype(int)\n",
    "    elif method == 'any':\n",
    "        # Flag as anomaly if any model detects it\n",
    "        ensemble = (predictions_array.sum(axis=0) > 0).astype(int)\n",
    "    elif method == 'all':\n",
    "        # Flag as anomaly only if all models detect it\n",
    "        ensemble = (predictions_array.sum(axis=0) == len(predictions_dict)).astype(int)\n",
    "    \n",
    "    return ensemble\n",
    "\n",
    "# Ensemble predictions\n",
    "ensemble_dict = {\n",
    "    'iso_forest': iso_pred_test,\n",
    "    'ocsvm': ocsvm_pred_test,\n",
    "    'lof': lof_pred_test,\n",
    "    'autoencoder': ae_pred_test\n",
    "}\n",
    "\n",
    "ensemble_pred = ensemble_predictions(ensemble_dict, method='majority')\n",
    "\n",
    "print(f\"Ensemble - Test anomalies: {ensemble_pred.sum()}\")\n",
    "\n",
    "if supervised and y_test is not None:\n",
    "    print(\"\\n=== ENSEMBLE MODEL ===\")\n",
    "    print(classification_report(y_test, ensemble_pred))\n",
    "    print(f\"ROC-AUC: {roc_auc_score(y_test, ensemble_pred):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. ANOMALY ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.1 Analyze Detected Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get anomaly indices\n",
    "anomaly_indices = np.where(ae_pred_test == 1)[0]\n",
    "\n",
    "if len(anomaly_indices) > 0:\n",
    "    # Compare anomalies with normal samples\n",
    "    anomalies = X_test.iloc[anomaly_indices]\n",
    "    normals = X_test.iloc[ae_pred_test == 0]\n",
    "    \n",
    "    print(f\"\\nDetected {len(anomaly_indices)} anomalies\")\n",
    "    print(\"\\nAnomaly Statistics:\")\n",
    "    print(anomalies.describe())\n",
    "    \n",
    "    print(\"\\nNormal Statistics:\")\n",
    "    print(normals.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.2 Feature Importance for Anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(anomaly_indices) > 0:\n",
    "    # Calculate mean absolute difference from normal samples\n",
    "    feature_diff = np.abs(anomalies.mean() - normals.mean())\n",
    "    feature_diff = feature_diff.sort_values(ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    feature_diff[:15].plot(kind='bar')\n",
    "    plt.title('Top 15 Features Contributing to Anomalies')\n",
    "    plt.xlabel('Feature')\n",
    "    plt.ylabel('Mean Absolute Difference')\n",
    "    plt.xticks(rotation=45, ha='right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.3 PCA Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce to 2D using PCA\n",
    "pca = PCA(n_components=2)\n",
    "X_test_pca = pca.fit_transform(X_test)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(X_test_pca[ae_pred_test == 0, 0], X_test_pca[ae_pred_test == 0, 1], \n",
    "           c='blue', label='Normal', alpha=0.5, s=20)\n",
    "plt.scatter(X_test_pca[ae_pred_test == 1, 0], X_test_pca[ae_pred_test == 1, 1], \n",
    "           c='red', label='Anomaly', alpha=0.8, s=50, marker='x')\n",
    "plt.xlabel(f'PC1 ({pca.explained_variance_ratio_[0]:.2%} variance)')\n",
    "plt.ylabel(f'PC2 ({pca.explained_variance_ratio_[1]:.2%} variance)')\n",
    "plt.title('Anomaly Detection - PCA Visualization')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(range(len(test_mse)), test_mse, c=ae_pred_test, \n",
    "           cmap='RdYlBu_r', alpha=0.6)\n",
    "plt.axhline(y=threshold, color='r', linestyle='--', label='Threshold')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Reconstruction Error')\n",
    "plt.title('Reconstruction Error Distribution')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. REAL-TIME ANOMALY DETECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnomalyDetector:\n",
    "    \"\"\"Production-ready anomaly detector\"\"\"\n",
    "    \n",
    "    def __init__(self, model, scaler, threshold):\n",
    "        self.model = model\n",
    "        self.scaler = scaler\n",
    "        self.threshold = threshold\n",
    "        self.model.eval()\n",
    "    \n",
    "    def detect(self, data):\n",
    "        \"\"\"Detect anomalies in new data\"\"\"\n",
    "        # Preprocess\n",
    "        data_scaled = self.scaler.transform(data)\n",
    "        data_tensor = torch.FloatTensor(data_scaled).to(device)\n",
    "        \n",
    "        # Get reconstruction error\n",
    "        with torch.no_grad():\n",
    "            reconstruction = self.model(data_tensor)\n",
    "            mse = torch.mean((data_tensor - reconstruction) ** 2, dim=1)\n",
    "            mse = mse.cpu().numpy()\n",
    "        \n",
    "        # Detect anomalies\n",
    "        is_anomaly = (mse > self.threshold).astype(int)\n",
    "        \n",
    "        return is_anomaly, mse\n",
    "\n",
    "# Initialize detector\n",
    "detector = AnomalyDetector(autoencoder, scaler, threshold)\n",
    "\n",
    "# Test on new data\n",
    "# new_data = pd.DataFrame(...)  # Your new data\n",
    "# anomalies, scores = detector.detect(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 11. MODEL PERSISTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save autoencoder\n",
    "torch.save({\n",
    "    'model_state_dict': autoencoder.state_dict(),\n",
    "    'threshold': threshold,\n",
    "    'config': CONFIG\n",
    "}, 'anomaly_detector.pth')\n",
    "\n",
    "# Save scaler\n",
    "import joblib\n",
    "joblib.dump(scaler, 'scaler.pkl')\n",
    "\n",
    "# Save other models\n",
    "joblib.dump(iso_forest, 'isolation_forest.pkl')\n",
    "joblib.dump(ocsvm, 'ocsvm.pkl')\n",
    "joblib.dump(lof, 'lof.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 12. CONCLUSIONS & NEXT STEPS\n",
    "\n",
    "## Summary:\n",
    "- Best Model: [Model Name]\n",
    "- Precision: X.XX\n",
    "- Recall: X.XX\n",
    "- F1-Score: X.XX\n",
    "- Detected Anomaly Rate: X.X%\n",
    "\n",
    "## Next Steps:\n",
    "- [ ] Implement streaming anomaly detection\n",
    "- [ ] Add feedback loop for model improvement\n",
    "- [ ] Implement LSTM Autoencoder for sequence data\n",
    "- [ ] Deploy as microservice with API\n",
    "- [ ] Set up alerting system\n",
    "- [ ] Implement explainable AI for anomalies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
